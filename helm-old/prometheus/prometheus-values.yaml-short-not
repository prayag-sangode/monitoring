rbac:
  create: true

configmapReload:
  reloadUrl: ""

  env: []

  prometheus:
    enabled: true

    name: configmap-reload

    image:
      repository: quay.io/prometheus-operator/prometheus-config-reloader
      tag: v0.75.2
      digest: ""
      pullPolicy: IfNotPresent

    containerPort: 8080
    containerPortName: metrics

server:
  name: server

  image:
    repository: quay.io/prometheus/prometheus
    tag: ""
    digest: ""
    pullPolicy: IfNotPresent

  configPath: /etc/config/prometheus.yml

  ingress:
    enabled: true
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: "basic"
      nginx.ingress.kubernetes.io/auth-secret: "ai-foundation-htpasswd"
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"

    hosts:
      - prometheus.example.com
    tls:
      - secretName: prometheus-serving-tls
        hosts:
          - prometheus.example.com
    
  #nodeSelector:
  # cce.cloud.com/cce-nodepool: "microservice-cpu-small-pool"    

  persistentVolume:
    enabled: true
    statefulSetNameOverride: ""
    accessModes:
      - ReadWriteOnce
    labels: {}
    annotations: {}
    existingClaim: ""
    mountPath: /data
    size: 10Gi
    storageClass: "standard"
    #storageClass: "csi-disk"
    subPath: ""

  service:
    enabled: true

    annotations: {}
    labels: {}
    clusterIP: ""

    externalIPs: []

    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    servicePort: 80
    sessionAffinity: None
    type: ClusterIP

    gRPC:
      enabled: false
      servicePort: 10901

    statefulsetReplica:
      enabled: false
      replica: 0

    additionalPorts: []

serverFiles:
  alerting_rules.yml:
    groups:
      - name: test
        rules:
          - alert: TestAlert
            expr: vector(1)
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Test alert is firing."  
              description: "This is a test alert."
      - name: kubernetes-pods
        rules:
          - alert: PodDown
            expr: up == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Pod {{ $labels.pod }} is down"
              description: "The pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is down."

          - alert: ContainerCreatingFor5Minutes
            expr: |
              max by (namespace, pod) (
                kube_pod_status_phase{phase!="Running"}
              ) > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Pod '{{ $labels.pod }}' in namespace '{{ $labels.namespace }}' is in a non-'Running' state for more than 5 minutes."
              description: "The pod '{{ $labels.pod }}' in namespace '{{ $labels.namespace }}' has been in a non-'Running' state for more than 5 minutes."

          - alert: PodHighCpuUsage
            expr: sum(rate(container_cpu_usage_seconds_total{job="kubelet", container_name!="POD"}[1m])) by (pod) > 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage in pod {{ $labels.pod }}"
              description: "The pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has high CPU usage."

          - alert: PodHighMemoryUsage
            expr: sum(container_memory_usage_bytes{job="kubelet", container_name!="POD"}) by (pod) / sum(machine_memory_bytes) by (node) > 0.8
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage in pod {{ $labels.pod }}"
              description: "The pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has high memory usage."

  prometheus.yml:
    rule_files:
      - /etc/config/recording_rules.yml
      - /etc/config/alerting_rules.yml
      - /etc/config/rules
      - /etc/config/alerts

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets: ['alertmanager.monitoring.svc.cluster.local:9093']        

    scrape_configs:
      - job_name: prometheus
        static_configs:
          - targets:
            - localhost:9090

      - job_name: alertmanager
        static_configs:
          - targets:
            - alertmanager-serving.monitoring.svc.cluster.local:9093

      - job_name: 'custom-pushgateway-service'
        honor_timestamps: true
        scrape_interval: 5s
        scrape_timeout: 4s
        metrics_path: /metrics
        scheme: http
        static_configs:
          - targets:
              - custom-metric-pushgateway.default.svc.cluster.local              

      - job_name: 'prometheus-pushgateway'
        honor_labels: true

        kubernetes_sd_configs:
          - role: service

        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: pushgateway

      - job_name: postgresql
        metrics_path: /metrics
        scrape_interval: 10s
        static_configs:
        - targets:
           - postgres-exporter-prometheus-postgres-exporter.monitoring.svc.cluster.local

      - job_name: kubernetes-nodes-cadvisor
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - replacement: kubernetes.default.svc:443
          target_label: __address__
        - regex: (.+)
          replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
          source_labels:
          - __meta_kubernetes_node_name
          target_label: __metrics_path__
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
             
alertmanager:
  enabled: false

  persistence:
    size: 100Gi

kube-state-metrics:
  enabled: true
  #nodeSelector:
  #  cce.cloud.com/cce-nodepool: "microservice-cpu-small-pool"      

prometheus-node-exporter:
  enabled: false

prometheus-pushgateway:
  enabled: true

  serviceAnnotations:
    prometheus.io/probe: pushgateway
  #nodeSelector:
  #  cce.cloud.com/cce-nodepool: "microservice-cpu-small-pool"      

